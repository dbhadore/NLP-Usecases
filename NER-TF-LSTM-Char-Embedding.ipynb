{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "133987ab",
   "metadata": {},
   "source": [
    "# Named Entity Recognition using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9ca2e7",
   "metadata": {},
   "source": [
    "## First with word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "983c10be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c23a8",
   "metadata": {},
   "source": [
    "##### Download data from https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus#ner_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e230a085",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7882f7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>responded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sentence #       Word  POS Tag\n",
       "1048570  Sentence: 47959       they  PRP   O\n",
       "1048571  Sentence: 47959  responded  VBD   O\n",
       "1048572  Sentence: 47959         to   TO   O\n",
       "1048573  Sentence: 47959        the   DT   O\n",
       "1048574  Sentence: 47959     attack   NN   O"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.fillna(method=\"ffill\")\n",
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "baae5867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35179"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "n_words = len(words); n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "864eb70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(set(data[\"Tag\"].values))\n",
    "n_tags = len(tags); n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d460e1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I-art',\n",
       " 'I-gpe',\n",
       " 'B-nat',\n",
       " 'I-eve',\n",
       " 'I-nat',\n",
       " 'I-org',\n",
       " 'B-per',\n",
       " 'B-gpe',\n",
       " 'B-art',\n",
       " 'I-geo',\n",
       " 'O',\n",
       " 'B-geo',\n",
       " 'B-eve',\n",
       " 'I-tim',\n",
       " 'B-tim',\n",
       " 'I-per',\n",
       " 'B-org']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0953a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "258fbc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27489"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx[\"Obama\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "141adab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx[\"B-geo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55413655",
   "metadata": {},
   "source": [
    "#### Parse data to extract sentences as (word, pos_tag, ner_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "db6b8455",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_group = data.groupby(\"Sentence #\").apply(lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                                                     s[\"POS\"].values.tolist(),\n",
    "                                                                                     s[\"Tag\"].values.tolist())])\n",
    "sentences = [s for s in sent_group]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164ee1e3",
   "metadata": {},
   "source": [
    "##### Create X and y with padding - 0 for X  and 'O' tag for y\n",
    "\n",
    "This data follows IOB tagging scheme, O means token belong to no chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f22105a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biggest sentence has 104 words\n"
     ]
    }
   ],
   "source": [
    "largest_sen = max(len(sen) for sen in sentences)\n",
    "print('biggest sentence has {} words'.format(largest_sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c4a8e394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.hist([len(sen) for sen in sentences], bins= 50, color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5acb942",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 75\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=0)\n",
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29b3778e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3201, 21110, 26786, 15265, 31585, 31720,   456, 32255, 24999,\n",
       "         4687, 20500,  7987, 19919,  6170,  3837,  4687,  4234, 21110,\n",
       "        22375, 34556, 27284, 23812, 32282,  1910,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0]),\n",
       " array([10, 10, 10, 10, 10, 10, 11, 10, 10, 10, 10, 10, 11, 10, 10, 10, 10,\n",
       "        10,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b763f6",
   "metadata": {},
   "source": [
    "##### Make y as categorical - One-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "747c6bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98c1959a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0][0], y[0][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf431528",
   "metadata": {},
   "source": [
    "##### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c508e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980d6cf8",
   "metadata": {},
   "source": [
    "##### CRF can be used in place of softmax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99a470bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input, Lambda\n",
    "#from tensorflow.contrib import CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38761b22",
   "metadata": {},
   "source": [
    "##### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64da1a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 75)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 75, 20)            703600    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 75, 100)           28400     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 75, 50)            5050      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 75, 17)            867       \n",
      "=================================================================\n",
      "Total params: 737,917\n",
      "Trainable params: 737,917\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(max_len,))\n",
    "model = Embedding(input_dim=n_words + 1, output_dim=20,\n",
    "                  input_length=max_len, mask_zero=True)(input)  # 20-dim embedding\n",
    "model = Bidirectional(LSTM(units=50, return_sequences=True,\n",
    "                           recurrent_dropout=0.1))(model)  # variational biLSTM\n",
    "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
    "out = Dense(n_tags, activation=\"softmax\")(model)\n",
    "# crf = CRF(n_tags)  # CRF layer\n",
    "# out = crf(model)  # output\n",
    "model = Model(input, out)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cf2ae5",
   "metadata": {},
   "source": [
    "##### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22a9729c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1214/1214 [==============================] - 108s 85ms/step - loss: 0.1177 - accuracy: 0.9040 - val_loss: 0.0501 - val_accuracy: 0.9515\n",
      "Epoch 2/5\n",
      "1214/1214 [==============================] - 107s 88ms/step - loss: 0.0362 - accuracy: 0.9633 - val_loss: 0.0357 - val_accuracy: 0.9637\n",
      "Epoch 3/5\n",
      "1214/1214 [==============================] - 115s 95ms/step - loss: 0.0261 - accuracy: 0.9726 - val_loss: 0.0336 - val_accuracy: 0.9662\n",
      "Epoch 4/5\n",
      "1214/1214 [==============================] - 114s 94ms/step - loss: 0.0218 - accuracy: 0.9766 - val_loss: 0.0329 - val_accuracy: 0.9668\n",
      "Epoch 5/5\n",
      "1214/1214 [==============================] - 114s 94ms/step - loss: 0.0190 - accuracy: 0.9790 - val_loss: 0.0340 - val_accuracy: 0.9668\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, np.array(y_train), batch_size=32, epochs=5, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdffd186",
   "metadata": {},
   "source": [
    "##### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "252ead6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 3s 14ms/step\n",
      "F1-score: 79.9%\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "test_pred = model.predict(X_test, verbose=1)\n",
    "\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "\n",
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i].replace(\"PAD\", \"O\"))\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "    \n",
    "pred_labels = pred2label(test_pred)\n",
    "test_labels = pred2label(y_test)\n",
    "\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93c76eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         art       0.00      0.00      0.00        39\n",
      "         eve       0.62      0.32      0.43        31\n",
      "         geo       0.82      0.88      0.84      3710\n",
      "         gpe       0.96      0.94      0.95      1538\n",
      "         nat       1.00      0.15      0.26        20\n",
      "         org       0.61      0.67      0.64      2027\n",
      "         per       0.73      0.70      0.71      1604\n",
      "         tim       0.87      0.84      0.85      2008\n",
      "\n",
      "   micro avg       0.79      0.81      0.80     10977\n",
      "   macro avg       0.70      0.56      0.59     10977\n",
      "weighted avg       0.79      0.81      0.80     10977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b468b6b",
   "metadata": {},
   "source": [
    "##### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3cffc238",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           ||True ||Pred\n",
      "==============================\n",
      "Officials      : O     O\n",
      "say            : O     O\n",
      "the            : O     O\n",
      "ship           : O     O\n",
      ",              : O     O\n",
      "the            : O     O\n",
      "Al             : B-org B-org\n",
      "Marwa          : I-org I-org\n",
      ",              : O     O\n",
      "was            : O     O\n",
      "carrying       : O     O\n",
      "some           : O     O\n",
      "3,000          : O     O\n",
      "tons           : O     O\n",
      "of             : O     O\n",
      "aid            : O     O\n",
      "when           : O     O\n",
      "it             : O     O\n",
      "was            : O     O\n",
      "stopped        : O     O\n",
      "by             : O     O\n",
      "the            : O     O\n",
      "Israeli        : B-gpe B-gpe\n",
      "navy           : O     O\n",
      ".              : O     O\n"
     ]
    }
   ],
   "source": [
    "i = 1000\n",
    "p = model.predict(np.array([X_test[i]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "true = np.argmax(y_test[i], -1)\n",
    "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(30 * \"=\")\n",
    "for w, t, pred in zip(X_test[i], true, p[0]):\n",
    "    if w != 0:\n",
    "        print(\"{:15}: {:5} {}\".format(words[w-1], tags[t], tags[pred]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9970de",
   "metadata": {},
   "source": [
    " # Enhancing LSTMs with character embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9e26143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_char = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "40f96170",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
    "word2idx[\"UNK\"] = 1\n",
    "word2idx[\"PAD\"] = 0\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "tag2idx = {t: i + 1 for i, t in enumerate(tags)}\n",
    "tag2idx[\"PAD\"] = 0\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f121a60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X_word = [[word2idx[w[0]] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c28b114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_word = pad_sequences(maxlen=max_len, sequences=X_word, value=word2idx[\"PAD\"], padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "62554abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "chars = set([w_i for w in words for w_i in w])\n",
    "n_chars = len(chars)\n",
    "print(n_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576fb7de",
   "metadata": {},
   "source": [
    "##### Character Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "84b867eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {c: i + 2 for i, c in enumerate(chars)}\n",
    "char2idx[\"UNK\"] = 1\n",
    "char2idx[\"PAD\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "63081ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34, 90, 93, 44, 80, 99, 70,  3, 80,  0],\n",
       "       [93, 62,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 3, 33, 58, 93, 70, 80, 36, 88, 99, 36],\n",
       "       [90, 99, 45, 33,  0,  0,  0,  0,  0,  0],\n",
       "       [58, 99, 88, 68, 90, 33,  3,  0,  0,  0],\n",
       "       [36, 90, 88, 93, 44, 24, 90,  0,  0,  0],\n",
       "       [72, 93, 70,  3, 93, 70,  0,  0,  0,  0],\n",
       "       [36, 93,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 7, 88, 93, 36, 33, 80, 36,  0,  0,  0],\n",
       "       [36, 90, 33,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [55, 99, 88,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [89, 70,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [53, 88, 99, 87,  0,  0,  0,  0,  0,  0],\n",
       "       [99, 70,  3,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 3, 33, 58, 99, 70,  3,  0,  0,  0,  0],\n",
       "       [36, 90, 33,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [55, 89, 36, 90,  3, 88, 99, 55, 99, 60],\n",
       "       [93, 62,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 5, 88, 89, 36, 89, 80, 90,  0,  0,  0],\n",
       "       [36, 88, 93, 93,  7, 80,  0,  0,  0,  0],\n",
       "       [62, 88, 93, 58,  0,  0,  0,  0,  0,  0],\n",
       "       [36, 90, 99, 36,  0,  0,  0,  0,  0,  0],\n",
       "       [68, 93, 44, 70, 36, 88, 28,  0,  0,  0],\n",
       "       [26,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_char = []\n",
    "for sentence in sentences:\n",
    "    sent_seq = []\n",
    "    for i in range(max_len):\n",
    "        word_seq = []\n",
    "        for j in range(max_len_char):\n",
    "            try:\n",
    "                word_seq.append(char2idx.get(sentence[i][0][j]))\n",
    "            except:\n",
    "                word_seq.append(char2idx.get(\"PAD\"))\n",
    "        sent_seq.append(word_seq)\n",
    "    X_char.append(np.array(sent_seq))\n",
    "X_char[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "47b84fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, value=tag2idx[\"PAD\"], padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e0a02dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_word_train, X_word_test, y_train, y_test = train_test_split(X_word, y, test_size=0.1, random_state=2018)\n",
    "X_char_train, X_char_test, _, _ = train_test_split(X_char, y, test_size=0.1, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "66218b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, TimeDistributed, Dropout, Conv1D\n",
    "from tensorflow.keras.layers import Bidirectional, concatenate, SpatialDropout1D, GlobalMaxPooling1D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05bb08d",
   "metadata": {},
   "source": [
    "##### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "56a71441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and embedding for words\n",
    "word_in = Input(shape=(max_len,))\n",
    "emb_word = Embedding(input_dim=n_words + 2, output_dim=20,\n",
    "                     input_length=max_len, mask_zero=True)(word_in)\n",
    "\n",
    "# input and embeddings for characters\n",
    "char_in = Input(shape=(max_len, max_len_char,))\n",
    "emb_char = TimeDistributed(Embedding(input_dim=n_chars + 2, output_dim=10,\n",
    "                           input_length=max_len_char, mask_zero=True))(char_in)\n",
    "# character LSTM to get word encodings by characters\n",
    "char_enc = TimeDistributed(LSTM(units=20, return_sequences=False,\n",
    "                                recurrent_dropout=0.5))(emb_char)\n",
    "\n",
    "# main LSTM\n",
    "x = concatenate([emb_word, char_enc])\n",
    "x = SpatialDropout1D(0.3)(x)\n",
    "main_lstm = Bidirectional(LSTM(units=50, return_sequences=True,\n",
    "                               recurrent_dropout=0.6))(x)\n",
    "out = TimeDistributed(Dense(n_tags + 1, activation=\"sigmoid\"))(main_lstm)\n",
    "\n",
    "model = Model([word_in, char_in], out)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "15d78407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_20 (InputLayer)           [(None, 75, 10)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_19 (InputLayer)           [(None, 75)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 75, 10, 10)   1000        input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 75, 20)       703620      input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 75, 20)       2480        time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 75, 40)       0           embedding_1[0][0]                \n",
      "                                                                 time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 75, 40)       0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 75, 100)      36400       spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 75, 18)       1818        bidirectional_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 745,318\n",
      "Trainable params: 745,318\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd026f4",
   "metadata": {},
   "source": [
    "##### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3b7370c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1214/1214 [==============================] - 205s 164ms/step - loss: 0.1445 - acc: 0.8716 - val_loss: 0.0624 - val_acc: 0.9396\n",
      "Epoch 2/10\n",
      "1214/1214 [==============================] - 217s 179ms/step - loss: 0.0481 - acc: 0.9535 - val_loss: 0.0396 - val_acc: 0.9605\n",
      "Epoch 3/10\n",
      "1214/1214 [==============================] - 222s 183ms/step - loss: 0.0350 - acc: 0.9657 - val_loss: 0.0345 - val_acc: 0.9654\n",
      "Epoch 4/10\n",
      "1214/1214 [==============================] - 223s 183ms/step - loss: 0.0299 - acc: 0.9700 - val_loss: 0.0322 - val_acc: 0.9672\n",
      "Epoch 5/10\n",
      "1214/1214 [==============================] - 219s 180ms/step - loss: 0.0272 - acc: 0.9721 - val_loss: 0.0316 - val_acc: 0.9675\n",
      "Epoch 6/10\n",
      "1214/1214 [==============================] - 219s 180ms/step - loss: 0.0254 - acc: 0.9736 - val_loss: 0.0308 - val_acc: 0.9681\n",
      "Epoch 7/10\n",
      "1214/1214 [==============================] - 2882s 2s/step - loss: 0.0239 - acc: 0.9748 - val_loss: 0.0302 - val_acc: 0.9690\n",
      "Epoch 8/10\n",
      "1214/1214 [==============================] - 202s 166ms/step - loss: 0.0227 - acc: 0.9759 - val_loss: 0.0301 - val_acc: 0.9687\n",
      "Epoch 9/10\n",
      "1214/1214 [==============================] - 207s 171ms/step - loss: 0.0218 - acc: 0.9766 - val_loss: 0.0300 - val_acc: 0.9688\n",
      "Epoch 10/10\n",
      "1214/1214 [==============================] - 215s 177ms/step - loss: 0.0209 - acc: 0.9773 - val_loss: 0.0299 - val_acc: 0.9693\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_word_train,\n",
    "                     np.array(X_char_train).reshape((len(X_char_train), max_len, max_len_char))],\n",
    "                    np.array(y_train).reshape(len(y_train), max_len, 1),\n",
    "                    batch_size=32, epochs=10, validation_split=0.1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8f5ba5",
   "metadata": {},
   "source": [
    "##### Predict Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "11bad875",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict([X_word_test,\n",
    "                        np.array(X_char_test).reshape((len(X_char_test),\n",
    "                                                     max_len, max_len_char))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "10770e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           ||True ||Pred\n",
      "==============================\n",
      "The            : O     O\n",
      "US             : B-org B-org\n",
      "Government     : I-org I-org\n",
      "is             : O     O\n",
      "also           : O     O\n",
      "a              : O     O\n",
      "major          : O     O\n",
      "revenue        : O     O\n",
      "source         : O     O\n",
      "for            : O     O\n",
      "Tuvalu         : B-org B-org\n",
      "because        : O     O\n",
      "of             : O     O\n",
      "payments       : O     O\n",
      "from           : O     O\n",
      "a              : O     O\n",
      "1988           : B-tim B-tim\n",
      "treaty         : O     O\n",
      "on             : O     O\n",
      "fisheries      : O     O\n",
      ".              : O     O\n"
     ]
    }
   ],
   "source": [
    "i = 1000\n",
    "p = np.argmax(y_pred[i], axis=-1)\n",
    "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(30 * \"=\")\n",
    "for w, t, pred in zip(X_word_test[i], y_test[i], p):\n",
    "    if w != 0:\n",
    "        print(\"{:15}: {:5} {}\".format(idx2word[w], idx2tag[t], idx2tag[pred]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5d4be4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
